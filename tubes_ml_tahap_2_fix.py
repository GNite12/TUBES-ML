# -*- coding: utf-8 -*-
"""Tubes ML Tahap 2 FIX

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oiBpdwlUsXOKHXZw9NkNSJ5Y-gtNzMmB
"""

#Import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Data
!gdown --id 1o5q4R7U67sa9ltjjLd7cOxWrAVoVRVFR
!gdown --id 1hBBtVEpkfk-A9gzmKiFnO-MEIrmnsMk1

data_train = pd.read_csv('kendaraan_train.csv')
data_test = pd.read_csv('kendaraan_test.csv')

data_train.head()

#Jumlah data setelah dihapus
data_train = data_train.dropna()
print(data_train.isna().sum(), '\n')
print("Jumlah data sekarang :",len(data_train))

#Menghilangkan kolom ID
data_train = data_train.drop(columns=['id'], axis = 1)

data_train.head()

data_train

plt.boxplot(data_train['Premi'])

plt.boxplot(data_train['Umur'])

plt.boxplot(data_train['Lama_Berlangganan'])

training_data = data_train.to_numpy()
training_data = training_data[:10000]

header = data_train.columns

#Melihat jumlah nilai yang ada pada suatu attribute
def unique_vals(rows, col):
    return set([row[col] for row in rows])

#Menghitung label/kelas
def class_counts(rows):
    counts = {}
    for row in rows:
        label = row[-1]
        if label not in counts:
            counts[label] = 0
        counts[label] += 1
    return counts

#Mengecek apakah suatu nilai di baris sudah berbentuk numeric atau belum
def is_numeric(value):
    return isinstance(value, int) or isinstance(value, float)

#Menentukan pertanyaan
class Question:
    def __init__(self, column, value):
        self.column = column
        self.value = value

    def match(self, example):
        val = example[self.column]
        if is_numeric(val):
            return val >= self.value
        else:
            return val == self.value

    def __repr__(self):
        condition = "=="
        if is_numeric(self.value):
            condition = ">="
        return "Is %s %s %s?" % (
            header[self.column], condition, str(self.value))

#Membagi 
def partition(rows, question):
    true_rows, false_rows = [], []
    for row in rows:
        if question.match(row):
            true_rows.append(row)
        else:
            false_rows.append(row)
    return true_rows, false_rows

#Mencari nilai gini
def gini(rows):
    counts = class_counts(rows)
    impurity = 1
    for lbl in counts:
        prob_of_lbl = counts[lbl] / float(len(rows))
        impurity -= prob_of_lbl**2
    return impurity

#Mencari nilai information gain (mencari attribute)
def info_gain(left, right, current_uncertainty):
    p = float(len(left)) / (len(left) + len(right))
    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)

#Mensplit nilai split terbaik
def find_best_split(rows):
    best_gain = 0  # melacak perolehan informasi terbaik
    best_question = None  
    current_uncertainty = gini(rows)
    n_features = len(rows[0]) - 1  # jumlah kolom

    for col in range(n_features):  # untuk setiap fitur

        values = set([row[col] for row in rows])  # nilai unik di kolom

        for val in values:  # untuk setiap nilai

            question = Question(col, val)

            # mencoba memisahkan kumpulan data
            true_rows, false_rows = partition(rows, question)

            # Lewati pemisahan ini jika tidak membagi dataset.
            if len(true_rows) == 0 or len(false_rows) == 0:
                continue

            # menghitung perolehan informasi dari pemisahan ini
            gain = info_gain(true_rows, false_rows, current_uncertainty)

            if gain >= best_gain:
                best_gain, best_question = gain, question

    return best_gain, best_question

#Membuat Daun
class Leaf:
    def __init__(self, rows):
        self.predictions = class_counts(rows)

#Membuat Node 
class Decision_Node:
    def __init__(self,
                 question,
                 true_branch,
                 false_branch):
        self.question = question
        self.true_branch = true_branch
        self.false_branch = false_branch

#Membuat Pohon 
def build_tree(rows):
    # Memisahkan setiap attribute data yang unik, menghitung
    #perolehan informasi, dan mengembalikan pertanyaan 
    #yang menghasilkan perolehan tertinggi.
    gain, question = find_best_split(rows)

    # Base case: no further info gain
    if gain == 0:
        return Leaf(rows)

    # menemukan fitur / nilai yang berguna untuk dipartisi.
    true_rows, false_rows = partition(rows, question)

    # Bangun cabang true secara rekursif.
    true_branch = build_tree(true_rows)

    # Bangun cabang false secara rekursif.
    false_branch = build_tree(false_rows)

    # Return a Question node.
    return Decision_Node(question, true_branch, false_branch)

#Mengoutputkan hasil dari pohon
def print_tree(node, spacing=""):
    """World's most elegant tree printing function."""

    # Base case: we've reached a leaf
    if isinstance(node, Leaf):
        print (spacing + "Predict", node.predictions)
        return

    # Print the question at this node
    print (spacing + str(node.question))

    # Call this function recursively on the true branch
    print (spacing + '--> True:')
    print_tree(node.true_branch, spacing + "  ")

    # Call this function recursively on the false branch
    print (spacing + '--> False:')
    print_tree(node.false_branch, spacing + "  ")

#Mendefinisikan variabel pohon
my_tree = build_tree(training_data)

#Klasifikasi Decision Tree
def classify(row, node):
    """See the 'rules of recursion' above."""

    # Base case: jika telah mencapai daun
    if isinstance(node, Leaf):
        return node.predictions

    # Putuskan apakah akan mengikuti cabang-benar atau cabang-palsu.
    if node.question.match(row):
        return classify(row, node.true_branch)
    else:
        return classify(row, node.false_branch)

#Mengoutputkan Daun
def print_leaf(counts):
    """A nicer way to print the predictions at a leaf."""
    total = sum(counts.values()) * 1.0
    probs = {}
    for lbl in counts.keys():
        probs[lbl] = str(int(counts[lbl] / total * 100)) + "%"
    return probs

#Mendefinisikan dataset untuk testing
testing_data = data_test.to_numpy()

#Menampilkan hasil akurasi berdasarkan confusion matrix
truepositive = 0
truenegative = 0
falsepositive = 0
falsenegative = 0
for row in testing_data:
    check = classify(row, my_tree)
    #print(check)
    for key in check:
      if(key == 0 and row[-1] == 0):
        truenegative += 1
      elif(key == 1 and row[-1] == 1):
        truepositive += 1
      elif(key == 0 and row[-1] == 1):
        falsepositive += 1
      elif(key == 1 and row[-1] == 0):
        falsenegative += 1
print("TN :", truenegative, "TP :", truepositive, "FP", falsepositive, "FN", falsenegative)
akurasi = (truepositive + truenegative)/(truepositive + truenegative + falsepositive + falsenegative)
print("keakuratan decision tree =", akurasi*100,"%")

data_train['Jenis_Kelamin']=data_train['Jenis_Kelamin'].map({"Pria": 1 ,"Wanita" : 0}).to_numpy()
data_train['Kendaraan_Rusak']=data_train['Kendaraan_Rusak'].map({"Tidak": 0 ,"Pernah" : 1}).to_numpy()
data_train['Umur_Kendaraan']=data_train['Umur_Kendaraan'].map({"< 1 Tahun": 0 ,"1-2 Tahun" : 1, "> 2 Tahun" : 2}).to_numpy()
data_test['Jenis_Kelamin']=data_test['Jenis_Kelamin'].map({"Pria": 1 ,"Wanita" : 0}).to_numpy()
data_test['Kendaraan_Rusak']=data_test['Kendaraan_Rusak'].map({"Tidak": 0 ,"Pernah" : 1}).to_numpy()
data_test['Umur_Kendaraan']=data_test['Umur_Kendaraan'].map({"< 1 Tahun": 0 ,"1-2 Tahun" : 1, "> 2 Tahun" : 2}).to_numpy()

#Menggunakan library untuk menggunakan model decision tree
from sklearn.tree import DecisionTreeClassifier

dc = DecisionTreeClassifier()
dc.fit(data_train.iloc[:,0:9], data_train.iloc[:,-1])
Y_pred_dc = dc.predict(data_test.iloc[:,0:9])

from sklearn import metrics
print("Accuracy:",metrics.accuracy_score(data_test.Tertarik, Y_pred_dc)*100)

datatesting = pd.DataFrame(testing_data)
datatesting

dataframe = pd.DataFrame(training_data)
dataframe

training_data